{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from env_model import make_env, create_env_model\n",
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "from pacman_util import num_pixels, mode_rewards, pix_to_target, rewards_to_target\n",
    "from a2c import get_actor_critic, CnnPolicy\n",
    "from i2a import convert_target_to_real\n",
    "from common.minipacman import MiniPacman  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nenvs = 16\n",
    "nsteps = 5\n",
    "envs = [make_env() for i in range(nenvs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "ob_space = envs.observation_space.shape\n",
    "ac_space = envs.action_space\n",
    "num_actions = envs.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "observation space (15, 19, 3)\n",
      "number of actions 5\n",
      "INFO:tensorflow:Restoring parameters from weights/model_100000.ckpt\n",
      "INFO:tensorflow:Restoring parameters from weights/env_model.ckpt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0.003508772",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-05cdf9914dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             })\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_target_to_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/Documents/CLVR/imagination-augmented-agents-tf/i2a.py\u001b[0m in \u001b[0;36mconvert_target_to_real\u001b[0;34m(batch_size, nw, nh, nc, imagined_state, imagined_reward)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mimagined_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagined_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mimagined_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_to_pix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagined_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     imagined_state = imagined_state.reshape((batch_size, nw, nh,\n\u001b[1;32m     78\u001b[0m         nc))\n",
      "\u001b[0;32m/home/andy/Documents/CLVR/imagination-augmented-agents-tf/pacman_util.py\u001b[0m in \u001b[0;36mtarget_to_pix\u001b[0;34m(imagined_states)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mto_pixel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpixel_to_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimagined_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pixel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.003508772"
     ]
    }
   ],
   "source": [
    "env = MiniPacman('regular', 1000)\n",
    "done = False\n",
    "states = env.reset()\n",
    "num_actions = ac_space.n\n",
    "nw, nh, nc = ob_space\n",
    "print('observation space', ob_space)\n",
    "print('number of actions', num_actions)\n",
    "steps = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the actor\n",
    "    with tf.variable_scope('actor'):\n",
    "        actor_critic = get_actor_critic(sess, nenvs, nsteps, ob_space,\n",
    "                ac_space, CnnPolicy, should_summary=False)\n",
    "    actor_critic.load('weights/model_100000.ckpt')\n",
    "    \n",
    "    # Load the critic\n",
    "    with tf.variable_scope('env_model'): \n",
    "        env_model = create_env_model(ob_space, num_actions, num_pixels,\n",
    "                len(mode_rewards['regular']), should_summary=False)\n",
    "\n",
    "    save_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='env_model')\n",
    "    loader = tf.train.Saver(var_list=save_vars)\n",
    "    loader.restore(sess, 'weights/env_model.ckpt')\n",
    "    \n",
    "    while not done:\n",
    "        steps += 1\n",
    "        actions, _, _ = actor_critic.act(np.expand_dims(states, axis=0))\n",
    "\n",
    "        onehot_actions = np.zeros((1, num_actions, nw, nh))\n",
    "        onehot_actions[range(1), actions] = 1\n",
    "        # Change so actions are the 'depth of the image' as tf expects\n",
    "        onehot_actions = onehot_actions.transpose(0, 2, 3, 1)\n",
    "\n",
    "        s, r = sess.run([env_model.imag_state, \n",
    "                                        env_model.imag_reward], \n",
    "                                       feed_dict={\n",
    "                env_model.input_states: np.expand_dims(states, axis=0),\n",
    "                env_model.input_actions: onehot_actions\n",
    "            })\n",
    "        \n",
    "        s, r = convert_target_to_real(1, nw, nh, nc, s, r)\n",
    "        \n",
    "        states, reward, done, _ = env.step(actions[0])\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(10,3))\n",
    "        plt.subplot(131)\n",
    "        plt.title(\"Imagined\")\n",
    "        plt.imshow(s[0])\n",
    "        plt.subplot(132)\n",
    "        plt.title(\"Actual\")\n",
    "        plt.imshow(states)\n",
    "        plt.show()\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    print('DONE', done)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
